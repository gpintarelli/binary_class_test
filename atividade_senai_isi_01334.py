# -*- coding: utf-8 -*-
"""Atividade_SENAI_ISI_01334.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ivbBDcC3H3qnMHjzgipXbY75atz9XbH-

# Startup & Load Data

**Clear variables**
"""

# Commented out IPython magic to ensure Python compatibility.
# %reset
print("--- Workspace clean ---")

"""---
**Main Maths and Graph Libs.**
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import scipy.stats as stats
import seaborn as sns   # matplotlib graph styles
import string           #alphabet seq.
print("--- Libs. Load OK ---")

"""---
**Load data from colab files**

PS: The files are manually loaded from your computer
"""

from google.colab import files
uploaded = files.upload()

FILE = 'X_train.csv'

alphabet_string = list(string.ascii_uppercase) # alphabet string for column names
temp = pd.read_csv(FILE)
[rows, columns] = temp.shape
del alphabet_string[columns:] # update values
del temp

data = pd.read_csv(FILE, names=alphabet_string) # panda dataframe
x = [x for x in range(len(data))]
[rows, columns] = data.shape # update values
print("--- CSV loaded:", FILE, "---")
print("--- Those are the training data ---")

"""# Train Data Pre-processing

Preview the some lines of the loaded data
"""

pd.set_option('display.max_columns', 21)
print("--- Check the training data ---")
print("--- Column automatic named in alphabetical order ---")
data

"""---
Calculate basic data description
"""

print("--- Basic train data description ---")
data.describe()
#data.isnull().values.any()

"""---
**Delete outliers**

PS: We defined outliers as a value that is more than 3 standard deviations (99.7%) from the mean. Attention here, we are supposing data to be described as normal data, this might provoke a small percentage data loss in the lower and top end.
"""

data_zscore = (data - data.mean())/data.std() # Calculate the standard score
abs_z_scores = np.abs(data_zscore)

filtered_entries = (abs_z_scores < 3).all(axis=1) # Outlier -> We defined as a value that is more than 3 standard deviations (99.7%) from the mean.
data_filtered = data[filtered_entries]
print("--- Outlayers removed ---")

"""---
**Check and remove duplicate columns**

PS: The function `getDuplicateColumns` does the auto check for duplicate columns




"""

from scipy.stats import pearsonr

def getDuplicateColumns(df):
    '''
    Get a list of duplicate columns.
    It will iterate over all the columns in dataframe and find the columns whose contents are duplicate.
    :param df: Dataframe object
    :return: List of columns whose contents are duplicates.
    '''
    duplicateColumnNames = set()
    # Iterate over all the columns in dataframe
    for x in range(df.shape[1]):
        # Select column at xth index.
        col = df.iloc[:, x]
        # Iterate over all the columns in DataFrame from (x+1)th index till end
        for y in range(x + 1, df.shape[1]):
            # Select column at yth index.
            otherCol = df.iloc[:, y]
            # Check if two columns at x 7 y index are equal

            corr, _ = pearsonr(col, otherCol) 
            if corr > 0.99: # OLD line: if col.equals(otherCol):
                duplicateColumnNames.add(df.columns.values[y])
    return list(duplicateColumnNames)

# REF: https://thispointer.com/how-to-find-drop-duplicate-columns-in-a-dataframe-python-pandas/ + adaptação correlação

print("--- Function loaded ---")

duplicateColumnNames = getDuplicateColumns(data_filtered)
print("--- Deleted dataframe col.:", duplicateColumnNames, " ---")

data_filtered = data_filtered.drop(columns=getDuplicateColumns(data_filtered)) # Delete duplicate columns (only works if columns are 100% equal)
print("--- Check the updated dataframe: ---")
data_filtered

"""**Dataframe to be used**

Calculate basic dataframe description
"""

print("--- Check the dataframe description (after pre-processing): ---")
data_filtered.describe()

"""**Dataframe Histograms (this will be used for training models)**"""

print("--- Check the dataframe histogram (after pre-processing): ---")
data_filtered.hist(figsize=(30,20), bins = 100)
plt.show()

"""# Unsupervised clustering with POPC

**Check for relevant columns**

We are looking for column data that have two distributions.

Our hypothesis is that this data will have two distribution and will probably will not be normal.
"""

alpha = 0.05

normal_test_df = {} # debug
normal_df_list = set()

for col in data_filtered:
  x = data_filtered[col]
  k2, p = stats.normaltest(x)
  #print("p = {:g}".format(p))

  normal_test_df[col] = 'Not classified'

  if p < alpha:  # null hypothesis: x comes from a normal distribution
      normal_test_df[col] = 'Non-normal'
  else:
      normal_test_df[col] = 'Normal'
      normal_df_list.add(col)#df.columns.values[y]

print("--- Check the distribution of the columns ---")
normal_test_df

"""---
**See the dataset to be diagnosed**

This is the filtered dataframe to be used on clustering

"""

print("--- Deleted dataframe col.:", normal_df_list, "---")

data_for_cluster_detect = data_filtered.drop(columns=normal_df_list) # Delete duplicate columns (only works if columns are 100% equal)
print("--- Check the updated dataframe: ---")
data_for_cluster_detect

print("--- Check the updated dataframe histogram ---")
data_for_cluster_detect.hist(figsize=(30,20), bins = 100)
plt.show()

"""---
**Powered Outer Probabilistic Clustering (POPC)**

We used the POPC method for clustering as [1]. 'Normal' k-means is common used in ML but was avoided as it is not recommended for binary data. k-means is a 'adapted 'back-propagation method. POPC seens to work well in the SENAI ISI data.

[1] REF Article: Powered Outer Probabilistic Clustering, Peter Taraba, 2017

REF: https://github.com/pepe78/POPC-examples-python

"""

from sklearn.cluster import KMeans

def deltaIfRemoved(row, counts, countsAll, numClusters, multiplier, power):
        ret = 0.0

        for i in range(len(row)):
                if row[i] == 1:
                        ret -= pow((counts[i] * multiplier + 1.0) / (countsAll[i] * multiplier + numClusters + 0.0), power)
                        ret += pow(((counts[i] - 1.0) * multiplier + 1.0) / (countsAll[i] * multiplier + numClusters + 0.0), power)

        return ret

def deltaIfAdded(row, counts, countsAll, numClusters, multiplier, power):
        ret = 0.0

        for i in range(len(row)):
                if row[i] == 1:
                        ret += pow(((counts[i] + 1.0) * multiplier + 1.0) / (countsAll[i] * multiplier + numClusters + 0.0), power)
                        ret -= pow((counts[i] * multiplier + 1.0) / (countsAll[i] * multiplier + numClusters + 0.0), power)

        return ret

def popc(samples, multiplier = 1000.0, power = 10.0):
        #kmeans = KMeans(n_clusters=int(len(samples)/2), random_state=0).fit(samples)
        kmeans = KMeans(n_clusters=int(2), random_state=0).fit(samples) # update, force 2 clusters

        labels = kmeans.labels_

        clusters = []
        clusters_counts = []
        counts_all = [0 for i in range(len(samples[0]))]
        for i in range(max(labels) + 1):
                clusters.append([])
                clusters_counts.append([0 for j in range(len(samples[0]))])

        for i in range(len(samples)):
                cs = samples[i]
                cl = labels[i]
                clusters[cl].append(i)

                for j in range(len(cs)):
                        if cs[j] == 1:
                                clusters_counts[cl][j] += 1
                                counts_all[j] += 1

        changed = True
        while changed:
                changed = False
                i = 0 
                while i < len(clusters):
                        j = 0
                        while j < len(clusters[i]):
                                largestGainWhere = -1
                                largestGain = -1.0
                                deltaBase = deltaIfRemoved(samples[clusters[i][j]], clusters_counts[i], counts_all, len(clusters), multiplier, power)
                                for k in range(len(clusters)):
                                        if i != k:
                                                delta = deltaBase + deltaIfAdded(samples[clusters[i][j]], clusters_counts[k], counts_all, len(clusters), multiplier, power)
                                                if delta > largestGain:
                                                        largestGain = delta
                                                        largestGainWhere = k
                                if largestGain > 0:
                                        changed = True
                                        cs = clusters[i][j]
                                        del clusters[i][j]
                                        clusters[largestGainWhere].append(cs)
                                        for k in range(len(samples[0])):
                                                if samples[cs][k] == 1:
                                                        clusters_counts[i][k] -= 1
                                                        clusters_counts[largestGainWhere][k] += 1
                                        j -= 1
                                j += 1
                        if len(clusters[i]) == 0:
                                del clusters[i]
                                del clusters_counts[i]
                                i -= 1
                        i += 1

        for i in range(len(clusters)):
                for j in range(len(clusters[i])):
                        labels[clusters[i][j]] = i
        
        return labels

def display(labelsWithSamples, title):
        fig = plt.gcf()
        fig.set_size_inches(12, 7)

        colors = ['b','g','r','c','m','y','k']
        labelsWithSamples = sorted(labelsWithSamples, key=lambda s: s[0])

        for i in range(len(labelsWithSamples)):
                for j in range(len(labelsWithSamples[i][1])):
                        if labelsWithSamples[i][1][j] == 1:
                                plt.plot(j, i, colors[labelsWithSamples[i][0] % 7] + 'o', markersize=1)

        plt.title(title)
        plt.show()

print("--- Functions loaded ---")

data_for_cluster_detect_round = data_for_cluster_detect.round(decimals=0) # round values to make it easier to the POPC algorithm
X = data_for_cluster_detect_round.values
X_index = data_for_cluster_detect_round.index
labels = popc(X)
result_clusters = []
for i in range(len(X)):
  result_clusters.append([labels[i], X[i]])

print("--- Check the binary clustering ---")
display(result_clusters, 'The found clusters {}'.format(1))

labels_df = pd.DataFrame(index=X_index)
labels_df
labels_df.insert(0, "_OUT", labels, True)

data_filtered_class = data_filtered.join(labels_df)

"""# Plots predicted clusters

**Some plots to see whats going on with clustering**
"""

print("--- Data used for clustering:", data_for_cluster_detect.columns.tolist(), "---")
g = sns.PairGrid(data_for_cluster_detect.join(labels_df), hue="_OUT")
g.map_diag(sns.histplot)
g.map_offdiag(sns.scatterplot)
g.add_legend()

"""# Load Test Data

**Load data from colab files**

PS: The files are manually added at Google Colab Files
"""

FILE1 = 'X_test.csv'
FILE2 = 'y_test.csv'

alphabet_string = list(string.ascii_uppercase) # alphabet string for column names
temp = pd.read_csv(FILE1)
[rows, columns] = temp.shape
del alphabet_string[columns:] # update values
del temp

data_X_test = pd.read_csv(FILE1, names=alphabet_string) # panda dataframe
data_y_test = pd.read_csv(FILE2, names=['_OUTR']) # panda dataframe


print("--- CSV loaded:", FILE1, "&", FILE2, "---")
print("--- Those are the validation data ---")

"""# ML Models

**Compare models for binary classification**

Models specified at `get_models`

We tested the 7 main models for binary classification (see [2]).
- Logistic Regression (LR)
- K-Nearest Neighbors (KNN)
- Decision Tree (DT)
- Support Vector Machine (SVM)
- Naive Bayes (NB)
- Random Forest (RF)
- Artificial Neural Network (ANN)

PS: SKlearn was used as the model library: https://scikit-learn.org/stable/

[2] REF:  Binary classification on French hospital data:
benchmark of 7 Machine Learning algorithms, Oliveira & Augusto, 2018. https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8616297 This article has a benchmark of 7 Machine Learning algorithms used on binary classification tasks. We did not test each model independently for fine tunning.
"""

# OLD debug: from sklearn.datasets import make_classification
# OLD debug: X, y = make_classification(n_samples=100, n_features=4, n_informative=2, random_state=1)

X = data_filtered.to_numpy()
y = labels

# summarize the dataset
print(X.shape, y.shape)

from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB
from sklearn.ensemble import RandomForestClassifier
from sklearn.neural_network import MLPClassifier

# get a list of models to evaluate
def get_models():
	models = dict()
	models['LR'] = LogisticRegression()
	models['KNN'] = KNeighborsClassifier()
	models['CART'] = DecisionTreeClassifier()
	models['SVM'] = SVC()
	models['BAYES'] = GaussianNB()
	models['RFO'] = RandomForestClassifier()
	models['MLP'] = MLPClassifier(max_iter=500) # Original max_iter is 100, but not converge
	return models

print("--- Classic models loaded ---")

"""---
**Test the models performance**

We used a simple parameter here (accuracy). Future implantation can use a more sophisticated performance comparison.
"""

from sklearn.metrics import classification_report
models = get_models()

X_train = data_filtered.values # We used all the available data (maybe there is complex interactions?)
Y_train = labels_df.values
#X_test = data_X_test.values # old
X_test = data_X_test.drop(columns=duplicateColumnNames).values # Delete duplicate columns as done with the X_train
Y_test = data_y_test.values

# evaluate the models and store results
results, names = list(), list()

print("--- We tested ---")
print("- Logistic Regression (LR)\n- K-Nearest Neighbors (KNN)\n- Decision Tree (DT)\n- Support Vector Machine (SVM)\n- Naive Bayes (NB)\n- Random Forest (RF)\n- Artificial Neural Network (ANN)\n")

print("Heres the accuracy of the models")
for name, model in models.items():
  model.fit(X_train, Y_train.ravel()) # Use .ravel here, https://stackoverflow.com/questions/34165731/a-column-vector-y-was-passed-when-a-1d-array-was-expected
  predicted = model.predict(X_test)
  report = classification_report(Y_test, predicted, output_dict=True) # Use output_dict=True to output 'text'
  results.append(report['accuracy'])
  names.append(name)
  print('>%s %.3f' % (name, report['accuracy'])) # Report variable can export more parameters from model, we used only accuracy

print("--- Check the bar graph for comparison ---")
fig = plt.figure()
ax = fig.add_axes([0,0,1,1])
ax.set_title('Accuracy of the models')
ax.bar(names,results)
plt.show()

"""---
**Get a stacking ensemble of models**

We add a 'stacking' model to be evaluated.

The function `get_models` is changed

The stacking method could be better optimize to test all available model combination possibilities (not done yet!). We tested the some of the combinations and we identify that the KNN+BAYES was the best performing.
"""

from sklearn.ensemble import StackingClassifier

# get a stacking ensemble of models
def get_stacking():
	# define the base models
  level0 = list()
  #level0.append(('LR', LogisticRegression()))
  level0.append(('KNN', KNeighborsClassifier()))
  #level0.append(('CART', DecisionTreeClassifier()))
  #level0.append(('SVM', SVC()))
  level0.append(('BAYES', GaussianNB()))
  #level0.append(('RFO', RandomForestClassifier()))
  #level0.append(('MLP', MLPClassifier(max_iter=500)))
  # define meta learner model
  level1 = LogisticRegression()
  # define the stacking ensemble
  model = StackingClassifier(estimators=level0, final_estimator=level1, cv=5)
  return model

print("--- Classic models + STACKING loaded ---")

# get a list of models to evaluate
def get_models():
	models = dict()
	models['LR'] = LogisticRegression()
	models['KNN'] = KNeighborsClassifier()
	models['CART'] = DecisionTreeClassifier()
	models['SVM'] = SVC()
	models['BAYES'] = GaussianNB()
	models['RFO'] = RandomForestClassifier()
	models['MLP'] = MLPClassifier(max_iter=500) # Original max_iter is 100, but not converge
	models['stacking'] = get_stacking()
	return models

models = get_models() # Here we add the stacking model

# evaluate the models and store results
results, names = list(), list()

for name, model in models.items():
  model.fit(X_train, Y_train.ravel())
  predicted = model.predict(X_test)
  report = classification_report(Y_test, predicted, output_dict=True) # Use output_dict=True to output 'text'
  results.append(report['accuracy'])
  names.append(name)
  print('>%s %.3f' % (name, report['accuracy'])) # Report variable can export more parameters from model, we used only accuracy

fig = plt.figure()
ax = fig.add_axes([0,0,1,1])
ax.set_title('Accuracy of the models')
ax.bar(names,results)
plt.show()

"""# Make a prediction for one value"""

# Some manual test
for i in range(15):
  yhat = model.predict([X_test[i]])
  print("Predicted Class:", yhat, "The 'gold' value:", Y_test[i])

# Test single data:
data = [[1,2,3,1,2,3,1,2,3,1,2,3,1,2]]
yhat = model.predict(data)
print("Predicted Class:", yhat)

"""# Refs links for coding

LINKS


http://www.leg.ufpr.br/~wagner/MCIE/Tutorial/TutorialV.html


https://jakevdp.github.io/PythonDataScienceHandbook/04.05-histograms-and-binnings.html


https://towardsdatascience.com/unsupervised-learning-for-anomaly-detection-44c55a96b8c1


https://www.programmersought.com/article/97537162463/


https://machinelearningmastery.com/types-of-classification-in-machine-learning/
"""